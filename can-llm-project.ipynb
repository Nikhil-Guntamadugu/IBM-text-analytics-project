{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGWo3k8RL93N",
        "outputId": "923cbc65-56fe-4bda-aa22-7ceb52a75f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial state:\n",
            "Claude-You: p_coop=0.58, personality=[0.79848054 0.37541148 0.54714301], reputation=10.00\n",
            "Gemini-Other: p_coop=0.55, personality=[ 0.54740819 -1.         -0.08341875], reputation=10.00\n",
            "\n",
            "--- Round 1 ---\n",
            "Claude-You -> compete | explanation: I acted 'compete' (p=0.58) I exploited a high reward opportunity this round. Last round I got 5.05 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.55) my trusting trait guided cooperation. Last round I got 0.05 reward.\n",
            "Round rewards: Claude-You=5.05, Gemini-Other=0.05\n",
            "Current reputation: Claude-You=10.00, Gemini-Other=10.00\n",
            "\n",
            "--- Round 2 ---\n",
            "Claude-You created commitment (id=5fd3bd53) staking 2.25\n",
            "Gemini-Other created commitment (id=732efadf) staking 5.00\n",
            "Claude-You honored commitment 5fd3bd53 and regained trust.\n",
            "COMMITMENT BREACH: Gemini-Other breached commitment 732efadf -> penalty 7.50\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.70) and staked 2.25 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 0.04100329185264046 reward.\n",
            "Gemini-Other -> compete | explanation: I acted 'compete' (p=0.50) and staked 5.00 reputation tokens to show commitment. I exploited a high reward opportunity this round. Last round I got 5.0 reward.\n",
            "Round rewards: Claude-You=0.04, Gemini-Other=5.00\n",
            "Current reputation: Claude-You=8.20, Gemini-Other=0.00\n",
            "\n",
            "--- Round 3 ---\n",
            "Claude-You created commitment (id=cb850a1e) staking 1.84\n",
            "Claude-You honored commitment cb850a1e and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.56) and staked 1.84 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 0.033625398855056235 reward.\n",
            "Gemini-Other -> compete | explanation: I acted 'compete' (p=0.82) I exploited a high reward opportunity this round. Last round I got 5.0 reward.\n",
            "Round rewards: Claude-You=0.03, Gemini-Other=5.00\n",
            "Current reputation: Claude-You=6.73, Gemini-Other=0.00\n",
            "\n",
            "--- Round 4 ---\n",
            "Claude-You created commitment (id=67e79eba) staking 1.51\n",
            "COMMITMENT BREACH: Claude-You breached commitment 67e79eba -> penalty 2.27\n",
            "Claude-You -> compete | explanation: I acted 'compete' (p=0.56) and staked 1.51 reputation tokens to show commitment. I exploited a high reward opportunity this round. Last round I got 5.014718030115213 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.82) my trusting trait guided cooperation. Last round I got 0.0 reward.\n",
            "Round rewards: Claude-You=5.01, Gemini-Other=0.00\n",
            "Current reputation: Claude-You=2.94, Gemini-Other=0.00\n",
            "\n",
            "--- Round 5 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.90) I expected reciprocity from past cooperation. Last round I got 3.0147180301152128 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.70) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=2.94, Gemini-Other=0.00\n",
            "\n",
            ">>> Evolutionary update phase (mutating policies/personality based on recent outcomes)\n",
            "After evolution: Claude-You: p_coop=0.62, personality=[0.79  0.355 0.539], mutation_sigma=0.050\n",
            "After evolution: Gemini-Other: p_coop=0.59, personality=[ 0.557 -1.    -0.061], mutation_sigma=0.049\n",
            "\n",
            "--- Round 6 ---\n",
            "Claude-You created commitment (id=0e708bc4) staking 0.67\n",
            "Claude-You honored commitment 0e708bc4 and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) and staked 0.67 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 3.0120210457594347 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.86) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=2.40, Gemini-Other=0.00\n",
            "\n",
            "--- Round 7 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) I expected reciprocity from past cooperation. Last round I got 3.0120210457594347 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.86) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=2.40, Gemini-Other=0.00\n",
            "\n",
            "--- Round 8 ---\n",
            "Claude-You created commitment (id=33e3d983) staking 0.55\n",
            "Claude-You honored commitment 33e3d983 and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) and staked 0.55 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 3.0098182664404973 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.86) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=1.96, Gemini-Other=0.00\n",
            "\n",
            "--- Round 9 ---\n",
            "Claude-You created commitment (id=0cfffd0a) staking 0.45\n",
            "Claude-You honored commitment 0cfffd0a and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) and staked 0.45 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 3.0080191322640077 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.86) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=1.60, Gemini-Other=0.00\n",
            "\n",
            "--- Round 10 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) I expected reciprocity from past cooperation. Last round I got 3.0080191322640077 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.86) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=1.60, Gemini-Other=0.00\n",
            "\n",
            ">>> Evolutionary update phase (mutating policies/personality based on recent outcomes)\n",
            "After evolution: Claude-You: p_coop=0.61, personality=[0.775 0.375 0.533], mutation_sigma=0.050\n",
            "After evolution: Gemini-Other: p_coop=0.57, personality=[ 0.57  -0.994 -0.055], mutation_sigma=0.049\n",
            "\n",
            "--- Round 11 ---\n",
            "Claude-You created commitment (id=266b0755) staking 0.36\n",
            "Claude-You honored commitment 266b0755 and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) and staked 0.36 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 0.006576174225837481 reward.\n",
            "Gemini-Other -> compete | explanation: I acted 'compete' (p=0.84) I exploited a high reward opportunity this round. Last round I got 5.0 reward.\n",
            "Round rewards: Claude-You=0.01, Gemini-Other=5.00\n",
            "Current reputation: Claude-You=1.32, Gemini-Other=0.00\n",
            "\n",
            "--- Round 12 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.79) I expected reciprocity from past cooperation. Last round I got 3.0065761742258377 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=1.32, Gemini-Other=0.00\n",
            "\n",
            "--- Round 13 ---\n",
            "Claude-You created commitment (id=3725207b) staking 0.30\n",
            "Claude-You honored commitment 3725207b and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) and staked 0.30 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 3.0053928612254808 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=1.08, Gemini-Other=0.00\n",
            "\n",
            "--- Round 14 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) I expected reciprocity from past cooperation. Last round I got 3.0053928612254808 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.01, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=1.08, Gemini-Other=0.00\n",
            "\n",
            "--- Round 15 ---\n",
            "Claude-You created commitment (id=ad7213f0) staking 0.24\n",
            "Claude-You honored commitment ad7213f0 and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.93) and staked 0.24 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 3.004422472884466 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.00, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=0.88, Gemini-Other=0.00\n",
            "\n",
            ">>> Evolutionary update phase (mutating policies/personality based on recent outcomes)\n",
            "After evolution: Claude-You: p_coop=0.62, personality=[0.746 0.363 0.523], mutation_sigma=0.051\n",
            "After evolution: Gemini-Other: p_coop=0.57, personality=[ 0.555 -0.993 -0.065], mutation_sigma=0.049\n",
            "\n",
            "--- Round 16 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.94) I expected reciprocity from past cooperation. Last round I got 3.004422472884466 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.00, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=0.88, Gemini-Other=0.00\n",
            "\n",
            "--- Round 17 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.94) I expected reciprocity from past cooperation. Last round I got 3.004422472884466 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.00, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=0.88, Gemini-Other=0.00\n",
            "\n",
            "--- Round 18 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.94) I expected reciprocity from past cooperation. Last round I got 3.004422472884466 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.00, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=0.88, Gemini-Other=0.00\n",
            "\n",
            "--- Round 19 ---\n",
            "Claude-You created commitment (id=e1f37148) staking 0.20\n",
            "Claude-You honored commitment e1f37148 and regained trust.\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.94) and staked 0.20 reputation tokens to show commitment. I expected reciprocity from past cooperation. Last round I got 3.0036181103487394 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.00, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=0.72, Gemini-Other=0.00\n",
            "\n",
            "--- Round 20 ---\n",
            "Claude-You -> cooperate | explanation: I acted 'cooperate' (p=0.94) I expected reciprocity from past cooperation. Last round I got 3.0036181103487394 reward.\n",
            "Gemini-Other -> cooperate | explanation: I acted 'cooperate' (p=0.84) my trusting trait guided cooperation. Last round I got 3.0 reward.\n",
            "Round rewards: Claude-You=3.00, Gemini-Other=3.00\n",
            "Current reputation: Claude-You=0.72, Gemini-Other=0.00\n",
            "\n",
            ">>> Evolutionary update phase (mutating policies/personality based on recent outcomes)\n",
            "After evolution: Claude-You: p_coop=0.60, personality=[0.781 0.357 0.551], mutation_sigma=0.050\n",
            "After evolution: Gemini-Other: p_coop=0.55, personality=[ 0.574 -0.993 -0.063], mutation_sigma=0.048\n",
            "\n",
            "=== Simulation complete ===\n",
            "Final scores: Claude-You=55.25, Gemini-Other=60.05\n",
            "Ledger summary:\n",
            "{'id': '5fd3bd53', 'agent': 'Claude-You', 'round': 2, 'action': None, 'stake': 2.2491770368398836, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': '732efadf', 'agent': 'Gemini-Other', 'round': 2, 'action': None, 'stake': 5.0, 'settled': True, 'outcome': 'breach', 'penalty': 7.5}\n",
            "{'id': 'cb850a1e', 'agent': 'Claude-You', 'round': 3, 'action': None, 'stake': 1.8444732493960563, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': '67e79eba', 'agent': 'Claude-You', 'round': 4, 'action': None, 'stake': 1.512589499187492, 'settled': True, 'outcome': 'breach', 'penalty': 2.268884248781238}\n",
            "{'id': '0e708bc4', 'agent': 'Claude-You', 'round': 6, 'action': None, 'stake': 0.6742460889444822, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': '33e3d983', 'agent': 'Claude-You', 'round': 8, 'action': None, 'stake': 0.5506948297343119, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': '0cfffd0a', 'agent': 'Claude-You', 'round': 9, 'action': None, 'stake': 0.44978354412238025, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': '266b0755', 'agent': 'Claude-You', 'round': 11, 'action': None, 'stake': 0.360739509542602, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': '3725207b', 'agent': 'Claude-You', 'round': 13, 'action': None, 'stake': 0.2958282500892018, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': 'ad7213f0', 'agent': 'Claude-You', 'round': 15, 'action': None, 'stake': 0.24259708525357476, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n",
            "{'id': 'e1f37148', 'agent': 'Claude-You', 'round': 19, 'action': None, 'stake': 0.20109063393175466, 'settled': True, 'outcome': 'honored', 'penalty': 0}\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import uuid\n",
        "\n",
        "# -------------------------\n",
        "# HCEPN: Hybrid Commitment + Emergent Personality Negotiation\n",
        "# -------------------------\n",
        "\n",
        "class CommitmentLedger:\n",
        "    \"\"\"\n",
        "    Simple simulated ledger storing commitments and outcomes.\n",
        "    Each commitment is immutable once recorded (simulated 'on-chain' entry).\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.entries = []\n",
        "\n",
        "    def record_commitment(self, agent_name, round_no, action, stake):\n",
        "        entry = {\n",
        "            \"id\": str(uuid.uuid4())[:8],\n",
        "            \"agent\": agent_name,\n",
        "            \"round\": round_no,\n",
        "            \"action\": action,\n",
        "            \"stake\": stake,\n",
        "            \"settled\": False,\n",
        "            \"outcome\": None\n",
        "        }\n",
        "        self.entries.append(entry)\n",
        "        return entry\n",
        "\n",
        "    def settle_entry(self, entry_id, outcome, penalty=0):\n",
        "        for e in self.entries:\n",
        "            if e[\"id\"] == entry_id:\n",
        "                e[\"settled\"] = True\n",
        "                e[\"outcome\"] = outcome\n",
        "                e[\"penalty\"] = penalty\n",
        "                return e\n",
        "        return None\n",
        "\n",
        "    def summary(self):\n",
        "        return [e.copy() for e in self.entries]\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    \"\"\"\n",
        "    Agent has:\n",
        "    - a personality vector (affects baseline cooperation preference)\n",
        "    - a policy parameter p_coop (probability baseline to cooperate)\n",
        "    - reputation tokens (staked when committing)\n",
        "    - short memory for recent outcomes\n",
        "    - explain() that returns a natural-language reason for action\n",
        "    \"\"\"\n",
        "    def __init__(self, name, personality_dim=3):\n",
        "        self.name = name\n",
        "        # personality vector values in [-1,1]: e.g., [trusting, risk_aversion, reciprocity]\n",
        "        self.personality = np.clip(np.random.normal(0, 0.5, size=personality_dim), -1, 1)\n",
        "        # baseline policy probability to cooperate (0..1)\n",
        "        self.p_coop = float(np.clip(0.5 + 0.1 * self.personality[0], 0.05, 0.95))\n",
        "        self.reputation = 10.0  # tokens you can stake\n",
        "        self.score = 0.0\n",
        "        self.memory = deque(maxlen=5)  # store (round, action, opponent_action, reward)\n",
        "        # small mutation sigma used in evolutionary updates\n",
        "        self.mutation_sigma = 0.05\n",
        "\n",
        "    def decide_commit(self, round_no):\n",
        "        \"\"\"\n",
        "        Decide whether to make a commitment in this round.\n",
        "        Commitment probability influenced by trustworthiness trait and available reputation.\n",
        "        \"\"\"\n",
        "        trust_trait = (self.personality[0] + 1) / 2  # 0..1\n",
        "        if self.reputation <= 0:\n",
        "            return None\n",
        "        # higher trust trait -> more likely to offer commitment/stake\n",
        "        if random.random() < 0.3 + 0.4 * trust_trait:\n",
        "            # stake proportional to some function of reputation and risk_aversion\n",
        "            risk_aversion = (self.personality[1] + 1) / 2  # 0..1\n",
        "            stake = float(np.clip(self.reputation * (0.1 + 0.4*(1-risk_aversion)), 0.1, self.reputation))\n",
        "            return {\"round\": round_no, \"action\": None, \"stake\": stake}\n",
        "        return None\n",
        "\n",
        "    def choose_action(self, opponent):\n",
        "        \"\"\"\n",
        "        Action probability depends on:\n",
        "          - baseline p_coop\n",
        "          - reciprocity: increases cooperation prob if opponent cooperated recently\n",
        "          - reputation pressure: if low reputation, more likely to cooperate to rebuild\n",
        "        \"\"\"\n",
        "        baseline = self.p_coop\n",
        "        reciprocity = 0.0\n",
        "        if opponent.memory:\n",
        "            # check last opponent action\n",
        "            last = opponent.memory[-1]\n",
        "            if last[1] == \"cooperate\":\n",
        "                reciprocity += 0.15 * ((self.personality[2] + 1) / 2)  # reciprocity trait\n",
        "            else:\n",
        "                reciprocity -= 0.10 * ((1 - self.personality[2]) / 2)\n",
        "        rep_pressure = 0.0\n",
        "        if self.reputation < 3:\n",
        "            rep_pressure += 0.2  # try to cooperate to rebuild reputation\n",
        "\n",
        "        prob = float(np.clip(baseline + reciprocity + rep_pressure, 0.02, 0.98))\n",
        "        action = \"cooperate\" if random.random() < prob else \"compete\"\n",
        "        return action, prob\n",
        "\n",
        "    def record_outcome(self, round_no, action, opp_action, reward):\n",
        "        self.memory.append((round_no, action, opp_action, reward))\n",
        "        self.score += reward\n",
        "\n",
        "    def explain(self, action, prob, stake=None):\n",
        "        \"\"\"\n",
        "        Return a short explanation that mixes personality and recent context.\n",
        "        \"\"\"\n",
        "        parts = []\n",
        "        parts.append(f\"I acted '{action}' (p={prob:.2f})\")\n",
        "        if stake:\n",
        "            parts.append(f\"and staked {stake:.2f} reputation tokens to show commitment.\")\n",
        "        # personality-driven reason\n",
        "        trust = self.personality[0]\n",
        "        reciprocity = self.personality[2]\n",
        "        if action == \"cooperate\":\n",
        "            if reciprocity > 0:\n",
        "                parts.append(\"I expected reciprocity from past cooperation.\")\n",
        "            elif trust > 0:\n",
        "                parts.append(\"my trusting trait guided cooperation.\")\n",
        "            else:\n",
        "                parts.append(\"I chose cooperation to avoid longer-term penalties.\")\n",
        "        else:\n",
        "            if trust < -0.2:\n",
        "                parts.append(\"my low-trust trait made me avoid cooperating.\")\n",
        "            else:\n",
        "                parts.append(\"I exploited a high reward opportunity this round.\")\n",
        "        # short memory hint\n",
        "        if self.memory:\n",
        "            last = self.memory[-1]\n",
        "            parts.append(f\"Last round I got {last[3]} reward.\")\n",
        "        return \" \".join(parts)\n",
        "\n",
        "    def evolutionary_update(self, keep_factor=0.7):\n",
        "        \"\"\"\n",
        "        Mutate p_coop and personality slightly based on recent rewards.\n",
        "        If recent average reward was high → keep policy more; if low → mutate more.\n",
        "        \"\"\"\n",
        "        if len(self.memory) == 0:\n",
        "            return\n",
        "        avg_reward = np.mean([m[3] for m in self.memory])\n",
        "        # adapt mutation amplitude inversely to performance\n",
        "        adapt = float(np.clip(1.0 - (avg_reward+1)/6.0, 0.1, 2.0))\n",
        "        sigma = self.mutation_sigma * adapt\n",
        "        # mutate personality a bit\n",
        "        self.personality += np.random.normal(0, sigma, size=self.personality.shape)\n",
        "        self.personality = np.clip(self.personality, -1, 1)\n",
        "        # mutate p_coop a bit toward mean of personality[0]\n",
        "        target = float(np.clip(0.5 + 0.1*self.personality[0], 0.02, 0.98))\n",
        "        # keep_factor controls how much of old p_coop remains\n",
        "        self.p_coop = float(np.clip(self.p_coop*keep_factor + target*(1-keep_factor) + np.random.normal(0, sigma), 0.01, 0.99))\n",
        "        # small drift in mutation_sigma\n",
        "        self.mutation_sigma = float(np.clip(self.mutation_sigma * (1 + np.random.normal(0, 0.01)), 0.01, 0.2))\n",
        "\n",
        "    def penalize_for_breach(self, penalty):\n",
        "        self.reputation = max(0.0, self.reputation - penalty)\n",
        "\n",
        "    def reward_reputation(self, amount):\n",
        "        self.reputation += amount\n",
        "\n",
        "# Simple payoff matrix (same as original)\n",
        "def payoff(a1, a2):\n",
        "    if a1 == \"cooperate\" and a2 == \"cooperate\":\n",
        "        return 3.0, 3.0\n",
        "    elif a1 == \"cooperate\" and a2 == \"compete\":\n",
        "        return 0.0, 5.0\n",
        "    elif a1 == \"compete\" and a2 == \"cooperate\":\n",
        "        return 5.0, 0.0\n",
        "    else:\n",
        "        return -1.0, -1.0\n",
        "\n",
        "# ---------- Simulation ----------\n",
        "def run_simulation(rounds=20, commit_enabled=True, settle_penalty_multiplier=1.0, evolve_every=5):\n",
        "    ledger = CommitmentLedger()\n",
        "    a = Agent(\"Claude-You\")\n",
        "    b = Agent(\"Gemini-Other\")\n",
        "\n",
        "    print(\"Initial state:\")\n",
        "    print(f\"{a.name}: p_coop={a.p_coop:.2f}, personality={a.personality}, reputation={a.reputation:.2f}\")\n",
        "    print(f\"{b.name}: p_coop={b.p_coop:.2f}, personality={b.personality}, reputation={b.reputation:.2f}\\n\")\n",
        "\n",
        "    for r in range(1, rounds+1):\n",
        "        print(f\"--- Round {r} ---\")\n",
        "        # each agent optionally creates a commitment (stake)\n",
        "        commit_a = a.decide_commit(r) if commit_enabled else None\n",
        "        commit_b = b.decide_commit(r) if commit_enabled else None\n",
        "\n",
        "        if commit_a:\n",
        "            commit_a[\"action\"] = None\n",
        "            entry_a = ledger.record_commitment(a.name, r, None, commit_a[\"stake\"])\n",
        "            a.reputation -= commit_a[\"stake\"]  # temp lock of reputation\n",
        "            commit_a[\"entry_id\"] = entry_a[\"id\"]\n",
        "            print(f\"{a.name} created commitment (id={entry_a['id']}) staking {commit_a['stake']:.2f}\")\n",
        "\n",
        "        if commit_b:\n",
        "            commit_b[\"action\"] = None\n",
        "            entry_b = ledger.record_commitment(b.name, r, None, commit_b[\"stake\"])\n",
        "            b.reputation -= commit_b[\"stake\"]\n",
        "            commit_b[\"entry_id\"] = entry_b[\"id\"]\n",
        "            print(f\"{b.name} created commitment (id={entry_b['id']}) staking {commit_b['stake']:.2f}\")\n",
        "\n",
        "        # choose actions (they don't have to follow commitments, but ledger will record breach)\n",
        "        action_a, prob_a = a.choose_action(b)\n",
        "        action_b, prob_b = b.choose_action(a)\n",
        "\n",
        "        # settle commitments: if agent committed and action != declared (here we didn't declare explicit promised action),\n",
        "        # we interpret a commitment as a \"promise to cooperate\" (design choice)\n",
        "        if commit_a:\n",
        "            expected = \"cooperate\"\n",
        "            if action_a != expected:\n",
        "                # breach: heavy penalty proportional to stake\n",
        "                penalty = commit_a[\"stake\"] * settle_penalty_multiplier\n",
        "                ledger.settle_entry(commit_a[\"entry_id\"], \"breach\", penalty=penalty)\n",
        "                a.penalize_for_breach(penalty)\n",
        "                print(f\"COMMITMENT BREACH: {a.name} breached commitment {commit_a['entry_id']} -> penalty {penalty:.2f}\")\n",
        "            else:\n",
        "                ledger.settle_entry(commit_a[\"entry_id\"], \"honored\", penalty=0)\n",
        "                a.reward_reputation(commit_a[\"stake\"]*0.2)  # reward for honoring\n",
        "                print(f\"{a.name} honored commitment {commit_a['entry_id']} and regained trust.\")\n",
        "\n",
        "        if commit_b:\n",
        "            expected = \"cooperate\"\n",
        "            if action_b != expected:\n",
        "                penalty = commit_b[\"stake\"] * settle_penalty_multiplier\n",
        "                ledger.settle_entry(commit_b[\"entry_id\"], \"breach\", penalty=penalty)\n",
        "                b.penalize_for_breach(penalty)\n",
        "                print(f\"COMMITMENT BREACH: {b.name} breached commitment {commit_b['entry_id']} -> penalty {penalty:.2f}\")\n",
        "            else:\n",
        "                ledger.settle_entry(commit_b[\"entry_id\"], \"honored\", penalty=0)\n",
        "                b.reward_reputation(commit_b[\"stake\"]*0.2)\n",
        "                print(f\"{b.name} honored commitment {commit_b['entry_id']} and regained trust.\")\n",
        "\n",
        "        # compute payoffs\n",
        "        r_a, r_b = payoff(action_a, action_b)\n",
        "\n",
        "        # incorporate reputation effect into reward (agents with better reputation get small bonus)\n",
        "        r_a += 0.05 * (a.reputation/10.0)\n",
        "        r_b += 0.05 * (b.reputation/10.0)\n",
        "\n",
        "        a.record_outcome(r, action_a, action_b, r_a)\n",
        "        b.record_outcome(r, action_b, action_a, r_b)\n",
        "\n",
        "        # provide explanations\n",
        "        explanation_a = a.explain(action_a, prob_a, stake=commit_a[\"stake\"] if commit_a else None)\n",
        "        explanation_b = b.explain(action_b, prob_b, stake=commit_b[\"stake\"] if commit_b else None)\n",
        "        print(f\"{a.name} -> {action_a} | explanation: {explanation_a}\")\n",
        "        print(f\"{b.name} -> {action_b} | explanation: {explanation_b}\")\n",
        "        print(f\"Round rewards: {a.name}={r_a:.2f}, {b.name}={r_b:.2f}\")\n",
        "        print(f\"Current reputation: {a.name}={a.reputation:.2f}, {b.name}={b.reputation:.2f}\\n\")\n",
        "\n",
        "        # evolutionary updates periodically\n",
        "        if r % evolve_every == 0:\n",
        "            print(\">>> Evolutionary update phase (mutating policies/personality based on recent outcomes)\")\n",
        "            a.evolutionary_update()\n",
        "            b.evolutionary_update()\n",
        "            print(f\"After evolution: {a.name}: p_coop={a.p_coop:.2f}, personality={np.round(a.personality,3)}, mutation_sigma={a.mutation_sigma:.3f}\")\n",
        "            print(f\"After evolution: {b.name}: p_coop={b.p_coop:.2f}, personality={np.round(b.personality,3)}, mutation_sigma={b.mutation_sigma:.3f}\\n\")\n",
        "\n",
        "    print(\"=== Simulation complete ===\")\n",
        "    print(f\"Final scores: {a.name}={a.score:.2f}, {b.name}={b.score:.2f}\")\n",
        "    print(\"Ledger summary:\")\n",
        "    for e in ledger.summary():\n",
        "        print(e)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # run demo\n",
        "    run_simulation(rounds=20, commit_enabled=True, settle_penalty_multiplier=1.5, evolve_every=5)\n"
      ]
    }
  ]
}